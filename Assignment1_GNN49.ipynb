{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-1 ( 15 Marks)\n",
    "\n",
    "## GNN Group 49\n",
    "\n",
    "## Group Member Names:\n",
    "1. Mukund Kumar (2023AA05458)\n",
    "2. Basant Singh Bhaskar (2023aa05512)\n",
    "3. Michael Joshua Glenn Marilyn (2023aa05394)\n",
    "4. Nagamalla Nitin Kumar (2023ab05106)\n",
    "5. Omkar Raju Iyer (2023aa05318)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part-1  ( 2 marks)\n",
    "\n",
    "Use the given dataset to design GNN based model for Node Classification as per details given below:\n",
    "\n",
    "Graph: The ogbn-products dataset is an undirected and unweighted graph, representing an Amazon product co-purchasing network [1]. Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. We follow [2] to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100.\n",
    "\n",
    "URL: https://ogb.stanford.edu/docs/nodeprop/#ogbn-productsLinks to an external site.\n",
    "\n",
    "You are expected to create Model using Pytorch Geometric MP-GNN based library.\n",
    "\n",
    "Do not copy existing model given in OGB site but create your own model.\n",
    "\n",
    "\n",
    "## Part-2 ( 1 Marks)\n",
    "\n",
    "Use https://ogb.stanford.edu/docs/home/Links to an external site. to learn dataset loading and checking performance method.\n",
    "\n",
    "\n",
    "## Part-3 ( 2X6 Marks)\n",
    "\n",
    "Based  on loaded dataset also compute following point:\n",
    "\n",
    "Diameter , number of nodes and edges , Global Clustering Coefficient of existing graph\n",
    "Plot the graph with label\n",
    " Refer Relevant material from Book related to Subgraph generation and provide explanation how you are generating subgraph\n",
    "Generate Node Induced Subgraph.\n",
    "Generate Node embedding using 2-hop method for all nodes in subgraph using MP-GNN library in PyTorch Geometric\n",
    "Plot Subgrpah and compute their Diameter.\n",
    " \n",
    "\n",
    "# Instruction for Student:\n",
    "\n",
    "Student is expected to use BITS Provided Labs and write Python code for model development.\n",
    "Pytorch Library and Pytorch Geometric Library can be used\n",
    "Python Library can be use\n",
    "NetworkX Library needs to use.\n",
    "This group assignment, so each member of group is expected to contribute evenly in completing the assignment.\n",
    "Assignment should be submitted in PDF format which contains Codes and their outcomes along with explanation.\n",
    "Link of Python code in BITS library needs to be given as we will be running the code in Lab environment.\n",
    "Each group has to work independently should not copy code or outcome of other group. If Plagiarism found the that will be dealt as per BITS Policy.\n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1  ( 2 marks)\n",
    "\n",
    "Use the given dataset to design GNN based model for Node Classification as per details given below:\n",
    "\n",
    "Graph: The **ogbn-products** dataset is an undirected and unweighted graph, representing an Amazon product co-purchasing network **[1]**. \n",
    "\n",
    "**Nodes represent products sold** in Amazon, and **edges between two products** indicate that the **products are purchased together**. \n",
    "\n",
    "We follow **[2]** to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100.\n",
    " \n",
    "\n",
    "URL: https://ogb.stanford.edu/docs/nodeprop/#ogbn-productsLinks to an external site.\n",
    "\n",
    "You are expected to create Model using Pytorch Geometric MP-GNN based library.\n",
    "\n",
    "Do not copy existing model given in OGB site but create your own model.\n",
    "\n",
    "### References\n",
    "[1] http://manikvarma.org/downloads/XC/XMLRepository.html\n",
    "\n",
    "[2] Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 257â€“266, 2019.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NX_CURGAPH_AUTOCONFIG=True\n",
    "import torch\n",
    "import torch_geometric as tgeo\n",
    "from torch_geometric.data import DataLoader\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.graphproppred import Evaluator\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# import cugraph as nx\n",
    "\n",
    "# SEED\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "tgeo.seed_everything(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "DEVICE = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\n",
    "print(f\"Device : {DEVICE}\")\n",
    "\n",
    "#!python -c \"import ogb; print(ogb.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_embedding(h, color, epoch=None, loss=None):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    h = h.detach().cpu().numpy()\n",
    "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
    "    if epoch is not None and loss is not None:\n",
    "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset format:\n",
    "\n",
    "The data files for all the datasets are in the following sparse representation format:\n",
    "\n",
    "Header Line: **Total_Points Num_Features Num_Labels**\n",
    "\n",
    "1 line per datapoint : **label1,label2,...labelk ft1:ft1_val ft2:ft2_val ft3:ft3_val .. ftd:ftd_val**\n",
    "\n",
    "For the small scale datasets, we have provided the complete data in one file. We have provided separate files for the train and test splits which contain the indices of the points that are in the train set and the test set. Each corresponding column of the split files contains a separate split.\n",
    "\n",
    "For the large scale datasets, we have provided a single train and test split individually in two separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ogbn-arxiv\"\n",
    "\n",
    "dataset = PygNodePropPredDataset(name=dataset_name)\n",
    "pyg_graph_data = dataset[0]\n",
    "\n",
    "\n",
    "print(\"Number of nodes: \", pyg_graph_data.num_nodes) # type: ignore\n",
    "print(\"Number of edges: \", pyg_graph_data.num_edges) # type: ignore\n",
    "print(\"Number of features per node: \", pyg_graph_data.num_features)\n",
    "print(\"Number of classes: \", dataset.num_classes)\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "# train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "# train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True) # type: ignore\n",
    "# validation_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=True) # type: ignore\n",
    "# test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=True) # type: ignore\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyg_graph_data.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GNN Model\n",
    "class GCN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, hidden_channel, out_channel):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.conv1 = tgeo.nn.GCNConv(in_channel, hidden_channel) # type: ignore\n",
    "        self.conv2 = tgeo.nn.GCNConv(hidden_channel, hidden_channel) # type: ignore\n",
    "        self.classifier = tgeo.nn.Linear(hidden_channel, out_channel) # type: ignore\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = torch.nn.functional.tanh(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = torch.nn.functional.tanh(h)  # Final GNN embedding space.\n",
    "\n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "\n",
    "model = GCN(dataset.num_features, 64, dataset.num_classes)\n",
    "print(model)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # Define optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    return loss, h\n",
    "\n",
    "for epoch in range(401):\n",
    "    loss, h = train(data)\n",
    "    if epoch % 10 == 0:\n",
    "        visualize_embedding(h, color=data.y, epoch=epoch, loss=loss)\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 ( 1 Marks)\n",
    "\n",
    "Use https://ogb.stanford.edu/docs/home/Links to an external site. to learn dataset loading and checking performance method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(name = dataset_name)\n",
    "# You can learn the input and output format specification of the evaluator as follows.\n",
    "# print(evaluator.expected_input_format) \n",
    "# print(evaluator.expected_output_format) \n",
    "input_dict = {\"y_true\": pyg_graph_data.y, \"y_pred\": y_pred}\n",
    "result_dict = evaluator.eval(input_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-3 ( 2X6 Marks)\n",
    "\n",
    "Based  on loaded dataset also compute following point:\n",
    "\n",
    "1. Diameter , \n",
    "2. number of nodes and edges , \n",
    "3. Global Clustering Coefficient of existing graph\n",
    "\n",
    "4. Plot the graph with label\n",
    "    Refer Relevant material from Book related to Subgraph generation and provide explanation how you are generating subgraph\n",
    "\n",
    "5. Generate Node-Induced Subgraph.\n",
    "6. Generate Node embedding using 2-hop method for all nodes in subgraph using MP-GNN library in PyTorch Geometric\n",
    "7. Plot Subgrpah and compute their Diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx_graph = tgeo.utils.to_networkx(pyg_graph_data, to_undirected=False) # type: ignore\n",
    "\n",
    "# (a) Diameter\n",
    "max_diameter = 0\n",
    "for component in nx.algorithms.components.connected_components(nx_graph):\n",
    "    nx_subgraph = nx_graph.subgraph(component).copy()\n",
    "    max_diameter = max(max_diameter, nx.algorithms.approximation.diameter(nx_subgraph))\n",
    "\n",
    "print(f\"Diameter of Graph : {max_diameter}\")\n",
    "\n",
    "\n",
    "# (b) Number of nodes and edges\n",
    "num_nodes = nx_graph.number_of_nodes()\n",
    "num_edges = nx_graph.number_of_edges()\n",
    "\n",
    "print(f\"Number of nodes : {num_nodes}\") # type: ignore\n",
    "print(f\"Number of edges : {num_edges}\") # type: ignore\n",
    "\n",
    "\n",
    "# (c) Global Clustering Coefficient of existing graph\n",
    "global_clustering_coefficient = nx.transitivity(nx_graph)\n",
    "print(f\"Global Clustering Coefficient : {global_clustering_coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Plot the Graph with Labels\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(nx_graph, with_labels=True, node_size=10, font_size=8)\n",
    "plt.title(\"Graph with Labels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (e) Generate Node-Induced Subgraph\n",
    "\n",
    "# Selecting 500 random nodes\n",
    "nodes = 100\n",
    "random_nodes = list(nx_graph.edges)[:nodes]\n",
    "nx_subgraph = nx_graph.edge_subgraph(random_nodes)\n",
    "\n",
    "# Plot the subgraph\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(nx_subgraph, with_labels=True, node_size=100)\n",
    "plt.title(f\"Node-Induced Subgraph {nodes} Edges\")\n",
    "plt.show()\n",
    "\n",
    "# Diameter of subgraph\n",
    "max_diameter = 0\n",
    "for component in nx.strongly_connected_components(nx_graph):\n",
    "    nx_subgraph = nx_graph.subgraph(component).copy()\n",
    "    max_diameter = max(max_diameter, nx.algorithms.approximation.diameter(nx_subgraph))\n",
    "\n",
    "print(f\"Diameter of subgraph : {max_diameter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (f) Generate Node Embeddings using 2-Hop method\n",
    "\n",
    "class TwoHopGNN(torch.nn.Module):\n",
    "    \"\"\"2-hop method for GNN\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(SEED)\n",
    "        self.conv1 = tgeo.nn.GCNConv(in_channels, hidden_channels) # type: ignore\n",
    "        self.conv2 = tgeo.nn.GCNConv(hidden_channels, hidden_channels) # type: ignore\n",
    "        self.classifier = torch.nn.Linear(hidden_channels, out_features=out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = torch.nn.functional.tanh(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = torch.nn.functional.tanh(h)\n",
    "\n",
    "         # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h\n",
    "    \n",
    "\n",
    "# Model\n",
    "model = TwoHopGNN(dataset.num_features, 10, dataset.num_classes)\n",
    "print(model)\n",
    "\n",
    "_, h = model(pyg_graph_data.x, pyg_graph_data.edge_index) # type: ignore\n",
    "print(f'Embedding shape: {list(h.shape)}')\n",
    "\n",
    "visualize_embedding(h, color=pyg_graph_data.y) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
